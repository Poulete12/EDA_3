{"title":"Analyse multivariée des élections présidentielles : Méthodes PCA et CCA","markdown":{"yaml":{"title":"Analyse multivariée des élections présidentielles : Méthodes PCA et CCA","author":"Asso et Antony","date":"`r Sys.Date()`","format":{"html":{"toc":true,"number-sections":true}},"execute":{"echo":false,"collapse":false,"message":false},"engine":"knitr"},"headingText":"Introduction","headingAttr":{"id":"","classes":["unnumbered"],"keyvalue":[]},"containsRefs":false,"markdown":"\n\n\nCe rapport présente une analyse multivariée des élections présidentielles parisiennes de **2007 à 2022** en mobilisant deux méthodes statistiques principales : l'**Analyse en Composantes Principales (PCA)** et l'**Analyse des Corrélations Canoniques (CCA)**.\n\n## Données et méthodes\n\nL'étude porte sur les résultats par bureau de vote parisien, regroupés en **sept familles politiques** : extrême gauche, gauche, écologistes, centre, droite, extrême droite et divers.\n\nNotre pipeline comprend :\n\n1.  **Extraction et nettoyage** des données électorales (formats parquet/Excel)\n\n2.  **Analyse PCA** pour explorer la structure politique de chaque élection\n\n3.  **Analyse CCA** pour mesurer la stabilité électorale entre scrutins consécutifs\n\nLes analyses CCA permettent d'identifier les bureaux de vote les plus stables/instables et de quantifier l'évolution du paysage électoral parisien sur quinze années.\n\n```{r}\n#| label: setup\n#| appendix: true\n#| include: false\nlibrary(CCA)\nlibrary(tidyverse)\nlibrary(arrow)\nlibrary(corrplot)\nlibrary(knitr)\nlibrary(factoextra)\nlibrary(readxl)\n```\n\n```{r}\n#| label: extractparquet\n#| appendix: true\n\n#Pour le moment je cherche uniquement les elections Europenne, Présidentielle et Régionalme car se sont les seuls qui sont sous le format parquet \n\nparquet_dir <- \"Data/Election/parquet\"\n\nparquet_files <- list.files(parquet_dir, full.names = TRUE)\n\n#Variable qui va permettre de socker toutes nos dataset\nall_elections <- list()\n\nfor (file in parquet_files) {\n  file_name <- tools::file_path_sans_ext(basename(file))\n  clean_name <- file_name %>%\n    str_remove(\"elections-\") %>%\n    str_replace(\"1ertour\",\"1t\") %>%\n    str_replace(\"2emetour\",\"2t\") %>%\n    str_replace_all(\"-\",\"_\")\n  \n  data <- read_parquet(file) \n  \n  all_elections[[clean_name]] <- data\n  \n}\n```\n\n# Extraction des données électorales\n\n## Sources et formats de données\n\nLes données électorales parisiennes proviennent de différentes sources institutionnelles (OpenData Paris, data.gouv.fr) et se présentent sous **deux formats principaux** :\n\n-   **Format Parquet** : Elections européennes, présidentielles et régionales\n\n-   **Format Excel** : Elections municipales et législatives\n\nCette hétérogénéité des formats nécessite le développement d'un pipeline d'extraction adaptatif capable de traiter chaque type de fichier avec les outils appropriés.\n\n## Processus d'extraction\n\nNotre pipeline d'extraction s'adapte automatiquement aux deux formats de données rencontrés :\n\n**Pour les fichiers Parquet**, le package **`arrow`** est particulièrement adapté à ce format optimisé pour les données volumineuses. Les noms de fichiers sont standardisés pour harmoniser la nomenclature.\n\n**Pour les fichiers Excel**, le package **`readxl`** permet de traiter les données municipales et législatives. Le processus comprend à corriger des noms de colonnes, la conversion des colonnes au format approprié quand nécessaire et la fusion de multiples fichiers Excel.\n\n```{r}\n#| label: extractxlsx\n#| appendix: true\n#| include: false\n\n# Fonction pour nettoyer les noms et prénoms\ncleaning_name <- function(text, type = \"person\") {\n  if (is.na(text) || is.null(text) || text == \"\") return(\"\")\n  \n  text_clean <- str_to_lower(text)\n  text_clean <- str_replace_all(text_clean, \"[àáâãäå]\", \"a\")\n  text_clean <- str_replace_all(text_clean, \"ç\", \"c\")\n  text_clean <- str_replace_all(text_clean, \"[èéêë]\", \"e\")\n  text_clean <- str_replace_all(text_clean, \"[ìíîï]\", \"i\")\n  text_clean <- str_replace_all(text_clean, \"ñ\", \"n\")\n  text_clean <- str_replace_all(text_clean, \"[òóôõöø]\", \"o\")\n  text_clean <- str_replace_all(text_clean, \"[ùúûü]\", \"u\")\n  text_clean <- str_replace_all(text_clean, \"[ýÿ]\", \"y\")\n  text_clean <- str_replace_all(text_clean, \"[^a-z]\", \"_\")\n  \n  if (type == \"column\") {\n    text_clean <- str_replace_all(text_clean, \"[ -]\", \"_\")\n    text_clean <- str_replace_all(text_clean, \"[ \\\\-'\\\"()\\\\[\\\\]]\", \"_\")\n  } \n  \n  text_clean <- str_replace_all(text_clean, \"_{2,}\", \"_\")\n  text_clean <- str_remove_all(text_clean, \"^_|_$\")\n  \n  return(text_clean)\n}\n\n#Fonction permettant de convertir en int \nconvert_to_numeric <- function(x) {\n    result <- as.numeric(as.character(x))\n    result[is.na(result)] <- 0\n    return(result)\n}\n\n#Fonction permettant l'extractions des fichiers excel\nextract_xls <- function(base_dir){  \n  new_data <- list()\n  dir_muni <- list.dirs(base_dir, full.names = FALSE, recursive = FALSE)\n  \n  for(dir in dir_muni){\n    dir_path <- file.path(base_dir,dir)\n    excel_files <- list.files(dir_path, full.names = TRUE)\n    regroup <- list()\n    \n    for(file in excel_files){\n      data <- read_excel(file,col_types = \"text\")\n      file_name <- basename(file)\n      regroup[[file_name]] <- data\n      \n    }\n    \n    #Leger préparation des collones \n    all_excel <- bind_rows(regroup)\n    \n    names(all_excel) <- sapply(names(all_excel), function(x) cleaning_name(x, type = \"column\"), USE.NAMES = FALSE)\n    \n    #Supprésion des colonnes vides\n    empty_cols <- which(names(all_excel) == \"\" | is.na(names(all_excel)))\n    \n    if(length(empty_cols) > 0) {\n      all_excel <- all_excel[, -empty_cols]\n    }\n    #Convertion des colonnes \n    columns_to_ignore <-  c(\"id_bvote\", \"scrutin\", \"annee\", \"date\")\n    columns_to_convert <- setdiff(names(all_excel), columns_to_ignore)\n    \n      \n    all_excel <- all_excel %>%\n      mutate(across(all_of(columns_to_convert), convert_to_numeric))\n    \n    new_data[[dir]] <- all_excel\n  }\n  return(new_data)\n}\n\n#Rajout dans notre liste all_elections\nmuni_data <- extract_xls(\"Data/Election/Municipale\")\nlegi_data <- extract_xls(\"Data/Election/Legislative\")\nall_elections <- c(all_elections, muni_data, legi_data)\n\n```\n\n```{r}\n#| label: kableallelections\n#| appendix: true\n\n\n# Extraction des informations depuis all_elections\nelections_info <- data.frame(\n  titre = character(),\n  tours = numeric(),\n  annee = numeric()\n)\n\nfor(name in names(all_elections)) {\n  if(grepl(\"presidentiel\", name, ignore.case = TRUE)) {\n    type <- \"Présidentielle\"\n  } else if(grepl(\"europeennes\", name, ignore.case = TRUE)) {\n    type <- \"Européenne\"\n  } else if(grepl(\"muni\", name, ignore.case = TRUE)) {\n    type <- \"Municipale\"\n  } else if(grepl(\"legi\", name, ignore.case = TRUE)) {\n    type <- \"Législative\"\n  } else if(grepl(\"regional\", name, ignore.case = TRUE)) {\n    type <- \"Régionale\"\n  } else {\n    type <- \"Autre\"\n  }\n  \n  annee <- as.numeric(str_extract(name, \"\\\\d{4}\"))\n  \n  if(grepl(\"_1t|_2t\", name)) {\n    tours <- ifelse(grepl(\"_2t\", name), 2, 1)\n  } else {\n    tours <- 1\n  }\n  \n  elections_info <- rbind(elections_info, \n                         data.frame(type, tours,annee))\n}\n\n\nkable(elections_info, \n      col.names = c(\"Titre\", \"Tours\", \"Année\"),\n      caption = \"Elections extraites et analysées\")\n```\n\n# Nettoyage des données\n\n## Harmonisation des variables et structure\n\nLes données extraites présentent plusieurs défis structurels nécessitant une standardisation avant analyse.\n\n**Suppression des colonnes non-pertinentes** : Les données brutes contiennent de nombreuses variables administratives et métadonnées non-essentielles pour l'analyse électorale (dates de création, identifiants géographiques redondants, informations de géolocalisation). Ces colonnes sont systématiquement supprimées pour alléger les datasets.\n\n**Harmonisation des noms** : Les tables présentent des noms de colonnes différents pour des concepts identiques.\n\n**Gestion des valeurs manquantes** : Toutes les valeurs manquantes (`NA`) sont remplacées par des zéros, correspondant logiquement à l'absence de votes pour un candidat dans un bureau donné.\n\n## Classification en familles politiques\n\n### Nécessité du regroupement\n\nLes données originales sont structurées par candidat individuel, rendant les comparaisons difficiles en raison des changements de personnalités politiques. Un regroupement en fonction de leur partie politique est donc nécessaire.\n\n### Processus de mapping\n\nLe mapping candidat à famille politique s'avère particulièrement complexe à réaliser manuellement. Les ressources en ligne fiables étant rares et souvent incomplètes, nous avons eu recours à une intelligence artificielle pour générer des fichiers CSV de correspondance sous notre supervision.\n\n## Sauvegarde standardisée\n\nChaque élection nettoyée est sauvegardée au format Parquet dans le répertoire `DataClean/`, produisant des fichiers homogènes avec une structure identique facilitant les analyses ultérieures. Le processus transforme des données hétérogènes par candidat en datasets cohérents par famille politique.\\\n\\\nPour illustrer le processus de nettoyage, voici un exemple concret avec les données des élections présidentielle 2022 du 1er tour :\"\n\n```{r}\n#| label: extract_xlsx\n#| appendix: true\nadmin_cols_possible <- c(\n  \"id_bv\", \"num_bureau\", \"id_arrondissement\", \"arr\", \"secteur\", \"quartier\",\n  \"nb_inscr\", \"nb_votant\", \"nb_exprim\", \"nb_bl_nul\", \"nb_blanc\", \"nb_nul\",\n  \"nb_vote_blanc\", \"nb_vote_nul\", \"nb_emarg\",\"nb_procu\", \n  \"circ_legislative\",\"type_election\"\n)\n\n\nfind_csv_file <- function(election_name, nuances_dir) {\n  # D'abord essayer le nom exact\n  exact_path <- file.path(nuances_dir, paste0(election_name, \".csv\"))\n  if (file.exists(exact_path)) {\n    return(exact_path)\n  }\n\n  base_name <- gsub(\"_[12]?t$|_t[12]$\", \"\", election_name)\n  base_path <- file.path(nuances_dir, paste0(base_name, \".csv\"))\n  \n  if (file.exists(base_path)) {\n    return(base_path)\n  }\n  \n  return(NULL)\n}\n\n#Mapping des tables\nmapping <- function(election_data, nuance_file_path, election_name) {\n  \n  candidats_nuances <- read_csv(nuance_file_path, show_col_types = FALSE)\n  \n  cols_candidats <- names(election_data)[!names(election_data) %in% admin_cols_possible]\n  \n  election_new <- election_data\n  \n  for (col_candidat in cols_candidats) {\n    # Trouver la nuance correspondante\n    nuance_candidat <- candidats_nuances$code_nuance[candidats_nuances$nom_prenom == col_candidat]\n    \n    if (length(nuance_candidat) > 0) {\n      nuance <- nuance_candidat[1]\n      \n      # Vérifier si une colonne avec cette nuance existe déjà\n      if (nuance %in% names(election_new)) {\n        # Additionner les valeurs\n        election_new[[nuance]] <- election_new[[nuance]] + election_new[[col_candidat]]\n        # Supprimer l'ancienne colonne candidat\n        election_new[[col_candidat]] <- NULL\n        \n      } else {\n        # Renommer la colonne\n        names(election_new)[names(election_new) == col_candidat] <- nuance\n      }\n      \n    } \n  }\n  \n  return(election_new)\n}\n\nhead(all_elections[[\"presidentielles_2022_1t\"]])\n```\n\nVoici le dataset après application du processus de nettoyage :\n\n```{r}\n#| label: nettoyage\n#| appendix: true\n# Nettoyage de chaque élection\nfor(name in names(all_elections)){\n  data <- all_elections[[name]]\n  \n  #On fussionne les votes nuls et blancs dans les data où elles sont séparées\n  blanc <- any(str_detect(names(data),\"nb_bl$|nb_blanc$|nb_vote_blanc$\"))\n  \n  exprim <-any(str_detect(names(data),\"nb_exprim$\"))\n    \n  if(blanc){\n    blanc_col <- names(data)[str_detect(names(data), \"nb_bl$|nb_blanc$|nb_vote_blanc$\")][1]\n    nul_col <- names(data)[str_detect(names(data), \"nb_nul$|nb_vote_nul$\")][1]\n    \n    data <- data %>%\n      mutate(\n        nb_bl_nul = as.numeric(!!sym(blanc_col)) + as.numeric(!!sym(nul_col))\n      ) %>%\n      select(-!!sym(blanc_col), -!!sym(nul_col)) %>%\n      relocate(nb_bl_nul, .after = nb_votant)\n  }\n  \n  if(exprim){\n     exprim_col <- names(data)[str_detect(names(data), \"nb_exprim$\")][1]\n  \n  data <- data %>%\n    rename(nb_exprime = !!sym(exprim_col))\n  }\n  \n    # On enlève les colonnes qu'on juge inutiles pour notre analyse en effet id_bvote contient toutes les informations sur l'emplacement du bureau de vote\n  cols_to_remove <- c(\"date\",\"created_user\", \"last_edited_user\",\n                      \"last_edited_date\",  \"created_date\", \n                      \"st_perimeter_shape\",\"st_area_shape\",\"nb_emarg\",\n                      \"scrutin\",\"circ_bv\",\"quartier_bv\",\"sec_bv\",\n                      \"numero_tour\",\"type_election\",\"date_tour\",\"arr_bv\",\n                      \"tour\",\"annee\",\"num_circ\",\"num_quartier\",\"num_arrond\",\n                      \"num_bureau\",\"geo_shape\",\"geo_point_2d\")\n  data <- data %>%\n    select(-any_of(cols_to_remove))\n  \n  # Convertir tous les NA en 0  \n  data <- data %>%\n    mutate(across(where(is.numeric), ~replace_na(.x, 0))) %>%\n    mutate(across(where(is.character), ~replace_na(.x, \"0\"))) \n  \n  # Chercher le fichier CSV de nuances correspondant\n  csv_file_path <- find_csv_file(name, \"Data/Nuance\")\n  \n  if (!is.null(csv_file_path)) {\n    data <- mapping(data, csv_file_path, name)\n  }\n  all_elections[[name]] <- data\n  \n  # Sauvegarder le résultat final\n  file_path <- file.path(\"DataClean\", paste0(name, \".parquet\"))\n  write_parquet(data, file_path)\n}\n\nhead(all_elections[[\"presidentielles_2022_1t\"]])\n```\n\n# **Analyses statistiques multivariées**\n\n## Analyse en Composantes Principales (PCA)\n\n### Objectif et méthodologie\n\nL'Analyse en Composantes Principales permet de réduire la dimensionnalité des données électorales tout en conservant l'information essentielle. Appliquée aux scores des sept familles politiques par bureau de vote, elle révèle les structures sous-jacentes du vote parisien.\n\nLa méthodologie consiste à :\n\n-   Calculer les scores par famille politique pour chaque bureau de vote\n\n-   Appliquer une PCA avec standardisation des variables\n\n-   Analyser la variance expliquée par les composantes principales\n\n-   Visualiser appropriées\n\nDans notre cas, nous appliquons la PCA aux **élections présidentielles de 2022, 2017, 2012** pour analyser l'évolution des structures politiques sur quinze années.\n\n### Résultat par élection\n\n**Élection présidentielle 2022**\n\n```{r}\n#| label: postPCA\n#| appendix: true\n  #On trie par nuance politique\nfamilles_nuance <- list(\n  \"EXTREME_GAUCHE\" = c(\"EXG\"),          \n  \"GAUCHE\" = c(\"COM\", \"SOC\",\"LFI\"),                  \n  \"ECOLOGISTES\" = c(\"ECO\"),                 \n  \"CENTRE\" = c(\"ENS\"),                        \n  \"DROITE\" = c(\"LR\",\"DVD\"),                       \n  \"EXTREME_DROITE\" = c(\"RN\", \"REC\"),         \n  \"DIVERS\" = c(\"DSV\", \"REG\")                \n)\n\n#Calcule des scores pour l'ensemble des parties\nscore <- function(data, familles){\n  scores_familles <- data %>%\n    mutate(\n      EXTREME_GAUCHE = rowSums(select(., any_of(familles$EXTREME_GAUCHE)), na.rm = TRUE),\n      GAUCHE = rowSums(select(., any_of(familles$GAUCHE)), na.rm = TRUE),\n      ECOLOGISTES = rowSums(select(., any_of(familles$ECOLOGISTES)), na.rm = TRUE),\n      CENTRE = rowSums(select(., any_of(familles$CENTRE)), na.rm = TRUE),\n      DROITE = rowSums(select(., any_of(familles$DROITE)), na.rm = TRUE),\n      EXTREME_DROITE = rowSums(select(., any_of(familles$EXTREME_DROITE)), na.rm = TRUE),\n      DIVERS = rowSums(select(., any_of(familles$DIVERS)), na.rm = TRUE)\n    )%>%\n     select(id_bvote,nb_exprime, all_of(names(familles)))\n    \n   \n  return(scores_familles)\n}\n\n\ndonnees <- read_parquet(\"DataClean/presidentielles_2022_1t.parquet\")\nscores_familles_2022 <- score(donnees,\n                              familles_nuance)\n\n```\n\n```{r}\n#| label: pca_2022\n#| appendix: true\n\nanalyser_pca <- function(data_dir, nom_analyse) {\n  \n  donnees <- read_parquet(data_dir)\n  \n  score_familles <- score(donnees,\n                             familles_nuance)\n  variables <- names(familles_nuance)\n  variables_valides <- variables[sapply(score_familles[variables],\n                                        function(x) var(x, na.rm = TRUE) > 0)]\n  # Calcul de la PCA\n  pca_resultat <- prcomp(score_familles[, variables_valides], scale. = TRUE)\n  \n  # Calcul de la variance expliquée\n  variance_expliquee <- summary(pca_resultat)$importance[2,] * 100\n  pc1_pct <- round(variance_expliquee[1], 1)\n  pc2_pct <- round(variance_expliquee[2], 1)\n  pc1_pc2_total <- round(pc1_pct + pc2_pct, 1)\n  \n  #Graphique des valeurs propres\n  print(fviz_eig(pca_resultat, \n               main = paste(\"Valeurs propres des élections \", nom_analyse, \n                           \"\\nPC1 + PC2 =\", pc1_pc2_total, \"%\")))\n  \n  #Graphique des variables\n  print(fviz_pca_var(pca_resultat,\n                col.var = \"contrib\", \n                gradient.cols = c(\"#00AFBB\", \"#E7B800\", \"#FC4E07\"),\n                repel = TRUE,\n                title = paste(\"Graphique des variables des élections \", nom_analyse))\n      )\n    \n  #Permet de savoir qui a été elu par burreau de vote\n  nuance_dominante <- variables_valides[apply(score_familles[,\n                                                      variables], 1, which.max)]\n  \n  #Graphique des individus\n  print(fviz_pca_ind(pca_resultat,\n                     geom.ind = \"point\",\n                     col.ind = as.factor(nuance_dominante),\n                     palette = c(\"#1F78B4\",\"#E31A1C\", \"#33A02C\", \"#FF7F00\", \"#6A3D9A\", \"#B15928\", \"#FFFF33\"),\n                     addEllipses = TRUE,\n                     ellipse.level = 0.95,\n                     title =  paste(\"Graphique des bureaux de vote des élections \", nom_analyse),\n                     legend.title = \"Nuance dominante\")\n        )\n      \n\n  return()\n}\n\nresultat_pca_2017 <- analyser_pca(\n  data_dir = \"DataClean/presidentielles_2022_1t.parquet\",\n  nom_analyse = \"Présidentielles 2022\"\n)\n```\n\nLa PCA révèle que les deux premières composantes expliquent **70,8% de la variance totale** (PC1 = 53%, PC2 = 18%).\n\n**Composante 1 (53%)** : Oppose clairement **gauche/extrême-gauche/écologistes** (scores négatifs) au **centre/droite/extrême-droite** (scores positifs). Cet axe reproduit le clivage idéologique classique gauche-droite.\n\n**Composante 2 (18%)** : Distingue l'**extrême-droite** (scores positifs) au reste (scores négatifs) )\n\nLa projection des bureaux de vote montre une **séparation nette** : les bureaux dominés par le centre (points bleus) se concentrent à droite, tandis que ceux dominés par la gauche (points rouges) se situent à gauche, avec très peu de chevauchement entre les ellipses.\n\n**Élection présidentielle 2017**\n\n```{r}\n#| label: pca_2017\n#| appendix: true\nresultat_pca_2017 <- analyser_pca(\"DataClean/presidentielles_2017_1t.parquet\",\n                                  \"Présidentielles 2017 \"\n                                 )\n```\n\nLa PCA explique **74,8% de la variance totale** avec les deux premières composantes (PC1 = 53,5%, PC2 = 21,3%).\n\n**Composante 1 (53,5%)** : Oppose la **droite traditionnelle (LR/Fillon)** (scores négatifs) au **bloc mixte gauche + extrême-droite + divers** (scores positifs). Cet axe ne suit pas le clivage gauche-droite classique mais distingue la droite modérée du reste du spectre politique.\n\n**Composante 2 (21,3%)** : Affine le vote \"radical\" en distinguant l'**extrême-droite FN** (scores positifs élevés) de la **gauche modérée/centre** (scores négatifs).\n\nLe nuage révèle **trois clusters bien distincts** avec des ellipses très séparées : droite classique LR/Fillon (PC1 \\< 0), gauche modérée PS/LFI/Hamon (PC1 \\< 0, PC2 \\> 0), et extrême-droite FN (PC1 \\> 0). Cette configuration illustre un paysage politique structuré en **trois îlots nets** plutôt qu'un clivage gauche-droite traditionnel comme évoqué précedement.\n\n**Élection présidentielle 2012**\n\n```{r}\n#| label: pca_2012\n#| appendix: true\nresultat_pca_2012 <- analyser_pca(\"DataClean/presidentielles_2012_1t.parquet\",\n                                  \"Présidentielles 2012\"\n                                 )\n```\n\n**Élection présidentielle 2012** La PCA explique **74,9% de la variance totale** avec les deux premières composantes (PC1 = 51,3%, PC2 = 23,6%).\n\n**Composante 1 (51,3%)** : Oppose la **droite modérée (UMP/Sarkozy)** (scores négatifs) au **bloc gauche + écologistes + extrêmes + divers** (scores positifs). Cet axe ne reproduit pas le clivage gauche-droite classique mais isole la droite modérée de l'ensemble du reste de l'échiquier politique.\n\n**Composante 2 (23,6%)** : Affine chaque bloc en distinguant les bureaux **écologie/gauche modérée** (scores positifs) des bureaux au reste des parties (scores négatifs).\n\nLe nuage montre une **séparation horizontale** : tous les bureaux \"gauche dominante\" (points rouges) se situent à droite (PC1 \\> 0), tandis que tous les bureaux \"extrême-droite dominante\" (points bleus) se placent à gauche (PC1 \\< 0)\n\n### Interprétation des structures politiques\n\nLes analyses PCA révèlent une **évolution majeure du paysage politique parisien** :\n\n**2012** : Structure classique avec isolation de la droite modérée (UMP) face au reste de l'échiquier politique.\n\n**2017** : **Recomposition en trois îlots distincts** - droite traditionnelle (LR), gauche modérée (PS/LFI), et extrême-droite (FN) - illustrant l'éclatement du système politique traditionnel.\n\n**2022** : **Retour à une bipolarisation** centre (Macron) versus gauche élargie, avec l'extrême-droite intégrée comme nuance verticale plutôt que comme bloc autonome.\n\nCette évolution montre le **passage d'un clivage gauche-droite classique** (2012) vers une **triangulation politique** (2017) puis vers une **nouvelle bipolarisation centre-gauche** (2022)\n\n### Rapprochement Centre-Droite en 2022\n\n### \n\n```{r}\n#| label: correlations\n#| appendix: true\ndata_2022 <- read_parquet(\"DataClean/presidentielles_2022_1t.parquet\")\nscore_familles_2022 <- score(data_2022,\n                             familles_nuance)\n\ncor_familles_2022 <- cor(score_familles_2022[, names(familles_nuance)])\n    corrplot_famille <- corrplot(cor_familles_2022, method = \"color\",\n                                 type = \"upper\",\n                                 addCoef.col = \"black\", tl.col = \"black\",\n                                 tl.srt = 45,\n             title = \"Corrélations familles politiques 2022\", mar = c(0,0,1,0))\n    \n\n```\n\nL'analyse suggère un retour vers un clivage similaire à 2012. Le graphique des variables PCA montre la proximité du centre et de la droite sur PC1, qui structure l'opposition gauche-droite. La matrice de corrélations confirme cette observation avec un coefficient de 0,75 entre ces deux familles politiques.\n\nCette forte corrélation indique une convergence électorale centre-droite rappelant les dynamiques de 2012, interrogeant ainsi l'évolution du paysage politique parisien.\n\n## Analyse des Corrélations Canoniques (CCA)\n\n### Objectif et méthodologie\n\nL'Analyse des Corrélations Canoniques mesure la stabilité électorale en comparant les bureaux de vote entre deux élections consécutives. Elle identifie les bureaux de vote ayant maintenu des comportements électoraux cohérents versus ceux ayant connu des basculements significatifs.\n\nLa méthodologie comprend :\n\n-   **Normalisation** : Conversion des scores en pourcentages par bureau de vote\n\n-   **Jointure** : Jointure naturel des données par identifiant de bureau (id_bvote)\n\n-   **CCA** : Calcul des corrélations canoniques et scores canoniques\n\n-   **Identification** : Bureaux instables\n\n### Résultats des comparaisons temporelles\n\n**Stabilité 2017-2022**\n\n```{r}\n#| label: CCA_2022\n#| appendix: true\n#| warning: false\n# Fonction pour analyser la stabilité électorale entre deux élections\nanalyser_stabilite_electorale <- function(data_A_path, data_B_path, anneeA, anneeB,\n                                          familles ) {\n  \n  donnees_A <- read_parquet(data_A_path)\n  donnees_B <- read_parquet(data_B_path)\n  \n  scores_A <- score(donnees_A, familles)\n  scores_B <- score(donnees_B, familles)\n  \n  # Calcul des pourcentages\n  variables_familles <- names(familles)\n  \n  #Mettre le score en pourcentage pour rendre cela a la même echelle\n  scores_A_pct <- scores_A %>%\n    mutate(across(all_of(variables_familles), \n                  ~ round(.x / nb_exprime * 100, 2))) %>%\n    select(id_bvote, paste0(variables_familles))\n  \n  scores_B_pct <- scores_B %>%\n    mutate(across(all_of(variables_familles), \n                  ~ round(.x / nb_exprime * 100, 2))) %>%\n    select(id_bvote, paste0(variables_familles))\n  \n  donnees_jointes <- inner_join(scores_A_pct, scores_B_pct, \n                                by = \"id_bvote\", suffix = c(\"_x\",\"_y\"))\n  \n  variables_x <- paste0(variables_familles, \"_x\")\n  variables_y <- paste0(variables_familles, \"_y\")\n  \n  # Filtrer les variables avec de la variance\n  variables_x_valides <- variables_x[sapply(donnees_jointes[variables_x], \n                                            function(x) var(x, na.rm = TRUE) > 0)]\n  variables_y_valides <- variables_y[sapply(donnees_jointes[variables_y], \n                                            function(x) var(x, na.rm = TRUE) > 0)]\n  \n  X <- as.matrix(donnees_jointes[, variables_x_valides])\n  Y <- as.matrix(donnees_jointes[, variables_y_valides])\n  \n  # Analyse Canonique\n  cca_resultat <- cc(X, Y)\n  correlations <- round(cca_resultat$cor, 4)\n  \n  # Interprétation de la stabilité\n  stabilite_globale <- correlations[1]\n  \n  # Calcul des scores canoniques\n  scores_canoniques_x <- X %*% cca_resultat$xcoef[, 1]\n  scores_canoniques_y <- Y %*% cca_resultat$ycoef[, 1]\n  \n  # Distance à la diagonale \n  distance_diagonale <- abs(scores_canoniques_x - scores_canoniques_y)\n  donnees_jointes$distance_diagonale <- distance_diagonale\n  donnees_jointes$score_x <- scores_canoniques_x\n  donnees_jointes$score_y <- scores_canoniques_y\n  \n  # Identification des bureaux les plus/moins stables\n  seuil_stabilite <- quantile(distance_diagonale, 0.9)\n  bureaux_instables <- donnees_jointes[distance_diagonale > seuil_stabilite, ]\n  \n  # Graphique diagonale de stabilité\n  p1 <- ggplot(donnees_jointes, aes(x = score_x, y = score_y)) +\n  geom_point(aes(color = distance_diagonale), alpha = 0.6, size = 1.5) +\n  geom_abline(slope = 1, intercept = 0, linetype = \"dashed\", color = \"red\", size = 1) +\n  labs(title = \"Stabilité électorale par bureau de vote \",\n       subtitle = paste0(\"Corrélation canonique: \", round(stabilite_globale, 3)),\n       x = paste0(\"Score canonique \", anneeA, \" (1er tour)\"),\n       y = paste0(\"Score canonique \", anneeB, \" (1er tour)\")) +\n  theme_minimal() +\n  theme(plot.title = element_text(hjust = 0.5),\n        plot.subtitle = element_text(hjust = 0.5))\n  \n  print(p1)\n  \n  tablo <- kable(bureaux_instables %>% \n            select(id_bvote, distance_diagonale, score_x, score_y) %>%\n            arrange(desc(distance_diagonale)) %>%\n            head(10),\n            col.names = c(\"Bureau de vote\", \"Distance diagonale\", \n                         paste0(\"Score \", anneeA), paste0(\"Score \", anneeB)),\n            digits = 3,\n            caption = paste0(\"Top 10 des bureaux les plus instables\"))\n  print(tablo)\n  \n  return()\n  \n}\n  resultat_stabilite <- analyser_stabilite_electorale(\n                      \"DataClean/presidentielles_2022_1t.parquet\",\n                      \"DataClean/presidentielles_2017_1t.parquet\",\n                      \"2022\",\n                      \"2017\",\n                       familles_nuance\n)\n    \n```\n\nLa corrélation canonique de **0,992** révèle une **fidélité électorale exceptionnelle** : la quasi-totalité des bureaux maintient un positionnement cohérent sur l'axe gauche-droite entre les deux scrutins.\n\nLe nuage de points s'aligne parfaitement sur la diagonale, confirmant que les bureaux conservent leur position relative. Dans cette analyse, les **scores faibles correspondent aux profils de gauche** (coefficients CCA négatifs pour PS/LFI) et les **scores élevés aux profils centre-droite** (coefficients CCA positifs pour LR/RN/En Marche) - cette convention étant déterminée par l'algorithme CCA.\n\nOn constate que les bureaux instable se caractérisés par un **basculement gauche centre-droite** : scores 2017 très négatifs versus scores 2022 très positifs.\n\nLe **13e arrondissement** concentre les plus fortes instabilités avec **3 bureaux dans le top 10**, dont le **bureau le plus instable** (13-33). Cela représente des \"poches de bascule\".\n\n```{r}\n#| label: CCA_2017\n#| appendix: true\n  resultat_stabilite <- analyser_stabilite_electorale(\n                      \"DataClean/presidentielles_2017_1t.parquet\",\n                      \"DataClean/presidentielles_2012_1t.parquet\",\n                      \"2017\",\n                      \"2012\",\n                       familles_nuance\n)\n```\n\nLa corrélation canonique de **0,949** indique une **forte stabilité électorale** entre ces deux scrutins.\n\n\\\nLe nuage de points se concentre majoritairement sur la diagonale, confirmant que les bureaux conservent leur positionnement relatif sur l'axe gauche-droite. Cependant, la stabilité est légèrement moindre qu'en 2017-2022.\n\nLes **10 bureaux les plus instables** présentent tous un **basculement gauche → centre-droite** : scores 2012 faibles (profil très à gauche/extrême) versus scores 2017 élevés (profil centre-droite). Le **17e arrondissement** domine avec plusieurs bureaux instables, illustrant des mutations locales où d'anciens bastions de gauche se sont convertis en zones centre-droite.\n\n## **Synthèse générale : Une méthodologie robuste pour comprendre les dynamiques électorales**\n\n**1. Validation méthodologique** Cette analyse démontre l'efficacité des **méthodes de factorisation matricielle (SVD/PCA/CCA)** pour l'analyse électorale :\n\n-   **PCA** : révèle les structures politiques et leur évolution temporelle\n\n-   **CCA** : quantifie précisément la stabilité électorale entre scrutins\n\n-   **Pipeline de nettoyage** : harmonise les données multi-temporelles\n\n**2. Découvertes sur le paysage politique parisien (2012-2022)**\n\n**Évolution structurelle en trois phases :**\n\n-   **2012** : Bipolarisation traditionnelle (droite modérée vs bloc gauche/écolo)\n\n-   **2017** : **Tripartition politique** (LR, PS/LFI, FN) - éclatement du système\n\n-   **2022** : **Nouvelle bipolarisation** (centre macroniste vs gauche élargie)\n\n**Stabilité paradoxale :**\n\n-   **Fidélité globale exceptionnelle** (corrélations 0,949 et 0,992)\n\n-   Mais **recompositions géographiquement concentrées** (13e, 17e arrondissements)\n\n-   **Direction unique des basculements** : gauche → centre-droite\n\n# **Appendix**\n\n```{r}\n#| label: appendix\n#| ref.label: !expr knitr::all_labels(appendix==TRUE)\n#| echo: true\n#| eval: false\n```\n","srcMarkdownNoYaml":"\n\n## Introduction {.unnumbered}\n\nCe rapport présente une analyse multivariée des élections présidentielles parisiennes de **2007 à 2022** en mobilisant deux méthodes statistiques principales : l'**Analyse en Composantes Principales (PCA)** et l'**Analyse des Corrélations Canoniques (CCA)**.\n\n## Données et méthodes\n\nL'étude porte sur les résultats par bureau de vote parisien, regroupés en **sept familles politiques** : extrême gauche, gauche, écologistes, centre, droite, extrême droite et divers.\n\nNotre pipeline comprend :\n\n1.  **Extraction et nettoyage** des données électorales (formats parquet/Excel)\n\n2.  **Analyse PCA** pour explorer la structure politique de chaque élection\n\n3.  **Analyse CCA** pour mesurer la stabilité électorale entre scrutins consécutifs\n\nLes analyses CCA permettent d'identifier les bureaux de vote les plus stables/instables et de quantifier l'évolution du paysage électoral parisien sur quinze années.\n\n```{r}\n#| label: setup\n#| appendix: true\n#| include: false\nlibrary(CCA)\nlibrary(tidyverse)\nlibrary(arrow)\nlibrary(corrplot)\nlibrary(knitr)\nlibrary(factoextra)\nlibrary(readxl)\n```\n\n```{r}\n#| label: extractparquet\n#| appendix: true\n\n#Pour le moment je cherche uniquement les elections Europenne, Présidentielle et Régionalme car se sont les seuls qui sont sous le format parquet \n\nparquet_dir <- \"Data/Election/parquet\"\n\nparquet_files <- list.files(parquet_dir, full.names = TRUE)\n\n#Variable qui va permettre de socker toutes nos dataset\nall_elections <- list()\n\nfor (file in parquet_files) {\n  file_name <- tools::file_path_sans_ext(basename(file))\n  clean_name <- file_name %>%\n    str_remove(\"elections-\") %>%\n    str_replace(\"1ertour\",\"1t\") %>%\n    str_replace(\"2emetour\",\"2t\") %>%\n    str_replace_all(\"-\",\"_\")\n  \n  data <- read_parquet(file) \n  \n  all_elections[[clean_name]] <- data\n  \n}\n```\n\n# Extraction des données électorales\n\n## Sources et formats de données\n\nLes données électorales parisiennes proviennent de différentes sources institutionnelles (OpenData Paris, data.gouv.fr) et se présentent sous **deux formats principaux** :\n\n-   **Format Parquet** : Elections européennes, présidentielles et régionales\n\n-   **Format Excel** : Elections municipales et législatives\n\nCette hétérogénéité des formats nécessite le développement d'un pipeline d'extraction adaptatif capable de traiter chaque type de fichier avec les outils appropriés.\n\n## Processus d'extraction\n\nNotre pipeline d'extraction s'adapte automatiquement aux deux formats de données rencontrés :\n\n**Pour les fichiers Parquet**, le package **`arrow`** est particulièrement adapté à ce format optimisé pour les données volumineuses. Les noms de fichiers sont standardisés pour harmoniser la nomenclature.\n\n**Pour les fichiers Excel**, le package **`readxl`** permet de traiter les données municipales et législatives. Le processus comprend à corriger des noms de colonnes, la conversion des colonnes au format approprié quand nécessaire et la fusion de multiples fichiers Excel.\n\n```{r}\n#| label: extractxlsx\n#| appendix: true\n#| include: false\n\n# Fonction pour nettoyer les noms et prénoms\ncleaning_name <- function(text, type = \"person\") {\n  if (is.na(text) || is.null(text) || text == \"\") return(\"\")\n  \n  text_clean <- str_to_lower(text)\n  text_clean <- str_replace_all(text_clean, \"[àáâãäå]\", \"a\")\n  text_clean <- str_replace_all(text_clean, \"ç\", \"c\")\n  text_clean <- str_replace_all(text_clean, \"[èéêë]\", \"e\")\n  text_clean <- str_replace_all(text_clean, \"[ìíîï]\", \"i\")\n  text_clean <- str_replace_all(text_clean, \"ñ\", \"n\")\n  text_clean <- str_replace_all(text_clean, \"[òóôõöø]\", \"o\")\n  text_clean <- str_replace_all(text_clean, \"[ùúûü]\", \"u\")\n  text_clean <- str_replace_all(text_clean, \"[ýÿ]\", \"y\")\n  text_clean <- str_replace_all(text_clean, \"[^a-z]\", \"_\")\n  \n  if (type == \"column\") {\n    text_clean <- str_replace_all(text_clean, \"[ -]\", \"_\")\n    text_clean <- str_replace_all(text_clean, \"[ \\\\-'\\\"()\\\\[\\\\]]\", \"_\")\n  } \n  \n  text_clean <- str_replace_all(text_clean, \"_{2,}\", \"_\")\n  text_clean <- str_remove_all(text_clean, \"^_|_$\")\n  \n  return(text_clean)\n}\n\n#Fonction permettant de convertir en int \nconvert_to_numeric <- function(x) {\n    result <- as.numeric(as.character(x))\n    result[is.na(result)] <- 0\n    return(result)\n}\n\n#Fonction permettant l'extractions des fichiers excel\nextract_xls <- function(base_dir){  \n  new_data <- list()\n  dir_muni <- list.dirs(base_dir, full.names = FALSE, recursive = FALSE)\n  \n  for(dir in dir_muni){\n    dir_path <- file.path(base_dir,dir)\n    excel_files <- list.files(dir_path, full.names = TRUE)\n    regroup <- list()\n    \n    for(file in excel_files){\n      data <- read_excel(file,col_types = \"text\")\n      file_name <- basename(file)\n      regroup[[file_name]] <- data\n      \n    }\n    \n    #Leger préparation des collones \n    all_excel <- bind_rows(regroup)\n    \n    names(all_excel) <- sapply(names(all_excel), function(x) cleaning_name(x, type = \"column\"), USE.NAMES = FALSE)\n    \n    #Supprésion des colonnes vides\n    empty_cols <- which(names(all_excel) == \"\" | is.na(names(all_excel)))\n    \n    if(length(empty_cols) > 0) {\n      all_excel <- all_excel[, -empty_cols]\n    }\n    #Convertion des colonnes \n    columns_to_ignore <-  c(\"id_bvote\", \"scrutin\", \"annee\", \"date\")\n    columns_to_convert <- setdiff(names(all_excel), columns_to_ignore)\n    \n      \n    all_excel <- all_excel %>%\n      mutate(across(all_of(columns_to_convert), convert_to_numeric))\n    \n    new_data[[dir]] <- all_excel\n  }\n  return(new_data)\n}\n\n#Rajout dans notre liste all_elections\nmuni_data <- extract_xls(\"Data/Election/Municipale\")\nlegi_data <- extract_xls(\"Data/Election/Legislative\")\nall_elections <- c(all_elections, muni_data, legi_data)\n\n```\n\n```{r}\n#| label: kableallelections\n#| appendix: true\n\n\n# Extraction des informations depuis all_elections\nelections_info <- data.frame(\n  titre = character(),\n  tours = numeric(),\n  annee = numeric()\n)\n\nfor(name in names(all_elections)) {\n  if(grepl(\"presidentiel\", name, ignore.case = TRUE)) {\n    type <- \"Présidentielle\"\n  } else if(grepl(\"europeennes\", name, ignore.case = TRUE)) {\n    type <- \"Européenne\"\n  } else if(grepl(\"muni\", name, ignore.case = TRUE)) {\n    type <- \"Municipale\"\n  } else if(grepl(\"legi\", name, ignore.case = TRUE)) {\n    type <- \"Législative\"\n  } else if(grepl(\"regional\", name, ignore.case = TRUE)) {\n    type <- \"Régionale\"\n  } else {\n    type <- \"Autre\"\n  }\n  \n  annee <- as.numeric(str_extract(name, \"\\\\d{4}\"))\n  \n  if(grepl(\"_1t|_2t\", name)) {\n    tours <- ifelse(grepl(\"_2t\", name), 2, 1)\n  } else {\n    tours <- 1\n  }\n  \n  elections_info <- rbind(elections_info, \n                         data.frame(type, tours,annee))\n}\n\n\nkable(elections_info, \n      col.names = c(\"Titre\", \"Tours\", \"Année\"),\n      caption = \"Elections extraites et analysées\")\n```\n\n# Nettoyage des données\n\n## Harmonisation des variables et structure\n\nLes données extraites présentent plusieurs défis structurels nécessitant une standardisation avant analyse.\n\n**Suppression des colonnes non-pertinentes** : Les données brutes contiennent de nombreuses variables administratives et métadonnées non-essentielles pour l'analyse électorale (dates de création, identifiants géographiques redondants, informations de géolocalisation). Ces colonnes sont systématiquement supprimées pour alléger les datasets.\n\n**Harmonisation des noms** : Les tables présentent des noms de colonnes différents pour des concepts identiques.\n\n**Gestion des valeurs manquantes** : Toutes les valeurs manquantes (`NA`) sont remplacées par des zéros, correspondant logiquement à l'absence de votes pour un candidat dans un bureau donné.\n\n## Classification en familles politiques\n\n### Nécessité du regroupement\n\nLes données originales sont structurées par candidat individuel, rendant les comparaisons difficiles en raison des changements de personnalités politiques. Un regroupement en fonction de leur partie politique est donc nécessaire.\n\n### Processus de mapping\n\nLe mapping candidat à famille politique s'avère particulièrement complexe à réaliser manuellement. Les ressources en ligne fiables étant rares et souvent incomplètes, nous avons eu recours à une intelligence artificielle pour générer des fichiers CSV de correspondance sous notre supervision.\n\n## Sauvegarde standardisée\n\nChaque élection nettoyée est sauvegardée au format Parquet dans le répertoire `DataClean/`, produisant des fichiers homogènes avec une structure identique facilitant les analyses ultérieures. Le processus transforme des données hétérogènes par candidat en datasets cohérents par famille politique.\\\n\\\nPour illustrer le processus de nettoyage, voici un exemple concret avec les données des élections présidentielle 2022 du 1er tour :\"\n\n```{r}\n#| label: extract_xlsx\n#| appendix: true\nadmin_cols_possible <- c(\n  \"id_bv\", \"num_bureau\", \"id_arrondissement\", \"arr\", \"secteur\", \"quartier\",\n  \"nb_inscr\", \"nb_votant\", \"nb_exprim\", \"nb_bl_nul\", \"nb_blanc\", \"nb_nul\",\n  \"nb_vote_blanc\", \"nb_vote_nul\", \"nb_emarg\",\"nb_procu\", \n  \"circ_legislative\",\"type_election\"\n)\n\n\nfind_csv_file <- function(election_name, nuances_dir) {\n  # D'abord essayer le nom exact\n  exact_path <- file.path(nuances_dir, paste0(election_name, \".csv\"))\n  if (file.exists(exact_path)) {\n    return(exact_path)\n  }\n\n  base_name <- gsub(\"_[12]?t$|_t[12]$\", \"\", election_name)\n  base_path <- file.path(nuances_dir, paste0(base_name, \".csv\"))\n  \n  if (file.exists(base_path)) {\n    return(base_path)\n  }\n  \n  return(NULL)\n}\n\n#Mapping des tables\nmapping <- function(election_data, nuance_file_path, election_name) {\n  \n  candidats_nuances <- read_csv(nuance_file_path, show_col_types = FALSE)\n  \n  cols_candidats <- names(election_data)[!names(election_data) %in% admin_cols_possible]\n  \n  election_new <- election_data\n  \n  for (col_candidat in cols_candidats) {\n    # Trouver la nuance correspondante\n    nuance_candidat <- candidats_nuances$code_nuance[candidats_nuances$nom_prenom == col_candidat]\n    \n    if (length(nuance_candidat) > 0) {\n      nuance <- nuance_candidat[1]\n      \n      # Vérifier si une colonne avec cette nuance existe déjà\n      if (nuance %in% names(election_new)) {\n        # Additionner les valeurs\n        election_new[[nuance]] <- election_new[[nuance]] + election_new[[col_candidat]]\n        # Supprimer l'ancienne colonne candidat\n        election_new[[col_candidat]] <- NULL\n        \n      } else {\n        # Renommer la colonne\n        names(election_new)[names(election_new) == col_candidat] <- nuance\n      }\n      \n    } \n  }\n  \n  return(election_new)\n}\n\nhead(all_elections[[\"presidentielles_2022_1t\"]])\n```\n\nVoici le dataset après application du processus de nettoyage :\n\n```{r}\n#| label: nettoyage\n#| appendix: true\n# Nettoyage de chaque élection\nfor(name in names(all_elections)){\n  data <- all_elections[[name]]\n  \n  #On fussionne les votes nuls et blancs dans les data où elles sont séparées\n  blanc <- any(str_detect(names(data),\"nb_bl$|nb_blanc$|nb_vote_blanc$\"))\n  \n  exprim <-any(str_detect(names(data),\"nb_exprim$\"))\n    \n  if(blanc){\n    blanc_col <- names(data)[str_detect(names(data), \"nb_bl$|nb_blanc$|nb_vote_blanc$\")][1]\n    nul_col <- names(data)[str_detect(names(data), \"nb_nul$|nb_vote_nul$\")][1]\n    \n    data <- data %>%\n      mutate(\n        nb_bl_nul = as.numeric(!!sym(blanc_col)) + as.numeric(!!sym(nul_col))\n      ) %>%\n      select(-!!sym(blanc_col), -!!sym(nul_col)) %>%\n      relocate(nb_bl_nul, .after = nb_votant)\n  }\n  \n  if(exprim){\n     exprim_col <- names(data)[str_detect(names(data), \"nb_exprim$\")][1]\n  \n  data <- data %>%\n    rename(nb_exprime = !!sym(exprim_col))\n  }\n  \n    # On enlève les colonnes qu'on juge inutiles pour notre analyse en effet id_bvote contient toutes les informations sur l'emplacement du bureau de vote\n  cols_to_remove <- c(\"date\",\"created_user\", \"last_edited_user\",\n                      \"last_edited_date\",  \"created_date\", \n                      \"st_perimeter_shape\",\"st_area_shape\",\"nb_emarg\",\n                      \"scrutin\",\"circ_bv\",\"quartier_bv\",\"sec_bv\",\n                      \"numero_tour\",\"type_election\",\"date_tour\",\"arr_bv\",\n                      \"tour\",\"annee\",\"num_circ\",\"num_quartier\",\"num_arrond\",\n                      \"num_bureau\",\"geo_shape\",\"geo_point_2d\")\n  data <- data %>%\n    select(-any_of(cols_to_remove))\n  \n  # Convertir tous les NA en 0  \n  data <- data %>%\n    mutate(across(where(is.numeric), ~replace_na(.x, 0))) %>%\n    mutate(across(where(is.character), ~replace_na(.x, \"0\"))) \n  \n  # Chercher le fichier CSV de nuances correspondant\n  csv_file_path <- find_csv_file(name, \"Data/Nuance\")\n  \n  if (!is.null(csv_file_path)) {\n    data <- mapping(data, csv_file_path, name)\n  }\n  all_elections[[name]] <- data\n  \n  # Sauvegarder le résultat final\n  file_path <- file.path(\"DataClean\", paste0(name, \".parquet\"))\n  write_parquet(data, file_path)\n}\n\nhead(all_elections[[\"presidentielles_2022_1t\"]])\n```\n\n# **Analyses statistiques multivariées**\n\n## Analyse en Composantes Principales (PCA)\n\n### Objectif et méthodologie\n\nL'Analyse en Composantes Principales permet de réduire la dimensionnalité des données électorales tout en conservant l'information essentielle. Appliquée aux scores des sept familles politiques par bureau de vote, elle révèle les structures sous-jacentes du vote parisien.\n\nLa méthodologie consiste à :\n\n-   Calculer les scores par famille politique pour chaque bureau de vote\n\n-   Appliquer une PCA avec standardisation des variables\n\n-   Analyser la variance expliquée par les composantes principales\n\n-   Visualiser appropriées\n\nDans notre cas, nous appliquons la PCA aux **élections présidentielles de 2022, 2017, 2012** pour analyser l'évolution des structures politiques sur quinze années.\n\n### Résultat par élection\n\n**Élection présidentielle 2022**\n\n```{r}\n#| label: postPCA\n#| appendix: true\n  #On trie par nuance politique\nfamilles_nuance <- list(\n  \"EXTREME_GAUCHE\" = c(\"EXG\"),          \n  \"GAUCHE\" = c(\"COM\", \"SOC\",\"LFI\"),                  \n  \"ECOLOGISTES\" = c(\"ECO\"),                 \n  \"CENTRE\" = c(\"ENS\"),                        \n  \"DROITE\" = c(\"LR\",\"DVD\"),                       \n  \"EXTREME_DROITE\" = c(\"RN\", \"REC\"),         \n  \"DIVERS\" = c(\"DSV\", \"REG\")                \n)\n\n#Calcule des scores pour l'ensemble des parties\nscore <- function(data, familles){\n  scores_familles <- data %>%\n    mutate(\n      EXTREME_GAUCHE = rowSums(select(., any_of(familles$EXTREME_GAUCHE)), na.rm = TRUE),\n      GAUCHE = rowSums(select(., any_of(familles$GAUCHE)), na.rm = TRUE),\n      ECOLOGISTES = rowSums(select(., any_of(familles$ECOLOGISTES)), na.rm = TRUE),\n      CENTRE = rowSums(select(., any_of(familles$CENTRE)), na.rm = TRUE),\n      DROITE = rowSums(select(., any_of(familles$DROITE)), na.rm = TRUE),\n      EXTREME_DROITE = rowSums(select(., any_of(familles$EXTREME_DROITE)), na.rm = TRUE),\n      DIVERS = rowSums(select(., any_of(familles$DIVERS)), na.rm = TRUE)\n    )%>%\n     select(id_bvote,nb_exprime, all_of(names(familles)))\n    \n   \n  return(scores_familles)\n}\n\n\ndonnees <- read_parquet(\"DataClean/presidentielles_2022_1t.parquet\")\nscores_familles_2022 <- score(donnees,\n                              familles_nuance)\n\n```\n\n```{r}\n#| label: pca_2022\n#| appendix: true\n\nanalyser_pca <- function(data_dir, nom_analyse) {\n  \n  donnees <- read_parquet(data_dir)\n  \n  score_familles <- score(donnees,\n                             familles_nuance)\n  variables <- names(familles_nuance)\n  variables_valides <- variables[sapply(score_familles[variables],\n                                        function(x) var(x, na.rm = TRUE) > 0)]\n  # Calcul de la PCA\n  pca_resultat <- prcomp(score_familles[, variables_valides], scale. = TRUE)\n  \n  # Calcul de la variance expliquée\n  variance_expliquee <- summary(pca_resultat)$importance[2,] * 100\n  pc1_pct <- round(variance_expliquee[1], 1)\n  pc2_pct <- round(variance_expliquee[2], 1)\n  pc1_pc2_total <- round(pc1_pct + pc2_pct, 1)\n  \n  #Graphique des valeurs propres\n  print(fviz_eig(pca_resultat, \n               main = paste(\"Valeurs propres des élections \", nom_analyse, \n                           \"\\nPC1 + PC2 =\", pc1_pc2_total, \"%\")))\n  \n  #Graphique des variables\n  print(fviz_pca_var(pca_resultat,\n                col.var = \"contrib\", \n                gradient.cols = c(\"#00AFBB\", \"#E7B800\", \"#FC4E07\"),\n                repel = TRUE,\n                title = paste(\"Graphique des variables des élections \", nom_analyse))\n      )\n    \n  #Permet de savoir qui a été elu par burreau de vote\n  nuance_dominante <- variables_valides[apply(score_familles[,\n                                                      variables], 1, which.max)]\n  \n  #Graphique des individus\n  print(fviz_pca_ind(pca_resultat,\n                     geom.ind = \"point\",\n                     col.ind = as.factor(nuance_dominante),\n                     palette = c(\"#1F78B4\",\"#E31A1C\", \"#33A02C\", \"#FF7F00\", \"#6A3D9A\", \"#B15928\", \"#FFFF33\"),\n                     addEllipses = TRUE,\n                     ellipse.level = 0.95,\n                     title =  paste(\"Graphique des bureaux de vote des élections \", nom_analyse),\n                     legend.title = \"Nuance dominante\")\n        )\n      \n\n  return()\n}\n\nresultat_pca_2017 <- analyser_pca(\n  data_dir = \"DataClean/presidentielles_2022_1t.parquet\",\n  nom_analyse = \"Présidentielles 2022\"\n)\n```\n\nLa PCA révèle que les deux premières composantes expliquent **70,8% de la variance totale** (PC1 = 53%, PC2 = 18%).\n\n**Composante 1 (53%)** : Oppose clairement **gauche/extrême-gauche/écologistes** (scores négatifs) au **centre/droite/extrême-droite** (scores positifs). Cet axe reproduit le clivage idéologique classique gauche-droite.\n\n**Composante 2 (18%)** : Distingue l'**extrême-droite** (scores positifs) au reste (scores négatifs) )\n\nLa projection des bureaux de vote montre une **séparation nette** : les bureaux dominés par le centre (points bleus) se concentrent à droite, tandis que ceux dominés par la gauche (points rouges) se situent à gauche, avec très peu de chevauchement entre les ellipses.\n\n**Élection présidentielle 2017**\n\n```{r}\n#| label: pca_2017\n#| appendix: true\nresultat_pca_2017 <- analyser_pca(\"DataClean/presidentielles_2017_1t.parquet\",\n                                  \"Présidentielles 2017 \"\n                                 )\n```\n\nLa PCA explique **74,8% de la variance totale** avec les deux premières composantes (PC1 = 53,5%, PC2 = 21,3%).\n\n**Composante 1 (53,5%)** : Oppose la **droite traditionnelle (LR/Fillon)** (scores négatifs) au **bloc mixte gauche + extrême-droite + divers** (scores positifs). Cet axe ne suit pas le clivage gauche-droite classique mais distingue la droite modérée du reste du spectre politique.\n\n**Composante 2 (21,3%)** : Affine le vote \"radical\" en distinguant l'**extrême-droite FN** (scores positifs élevés) de la **gauche modérée/centre** (scores négatifs).\n\nLe nuage révèle **trois clusters bien distincts** avec des ellipses très séparées : droite classique LR/Fillon (PC1 \\< 0), gauche modérée PS/LFI/Hamon (PC1 \\< 0, PC2 \\> 0), et extrême-droite FN (PC1 \\> 0). Cette configuration illustre un paysage politique structuré en **trois îlots nets** plutôt qu'un clivage gauche-droite traditionnel comme évoqué précedement.\n\n**Élection présidentielle 2012**\n\n```{r}\n#| label: pca_2012\n#| appendix: true\nresultat_pca_2012 <- analyser_pca(\"DataClean/presidentielles_2012_1t.parquet\",\n                                  \"Présidentielles 2012\"\n                                 )\n```\n\n**Élection présidentielle 2012** La PCA explique **74,9% de la variance totale** avec les deux premières composantes (PC1 = 51,3%, PC2 = 23,6%).\n\n**Composante 1 (51,3%)** : Oppose la **droite modérée (UMP/Sarkozy)** (scores négatifs) au **bloc gauche + écologistes + extrêmes + divers** (scores positifs). Cet axe ne reproduit pas le clivage gauche-droite classique mais isole la droite modérée de l'ensemble du reste de l'échiquier politique.\n\n**Composante 2 (23,6%)** : Affine chaque bloc en distinguant les bureaux **écologie/gauche modérée** (scores positifs) des bureaux au reste des parties (scores négatifs).\n\nLe nuage montre une **séparation horizontale** : tous les bureaux \"gauche dominante\" (points rouges) se situent à droite (PC1 \\> 0), tandis que tous les bureaux \"extrême-droite dominante\" (points bleus) se placent à gauche (PC1 \\< 0)\n\n### Interprétation des structures politiques\n\nLes analyses PCA révèlent une **évolution majeure du paysage politique parisien** :\n\n**2012** : Structure classique avec isolation de la droite modérée (UMP) face au reste de l'échiquier politique.\n\n**2017** : **Recomposition en trois îlots distincts** - droite traditionnelle (LR), gauche modérée (PS/LFI), et extrême-droite (FN) - illustrant l'éclatement du système politique traditionnel.\n\n**2022** : **Retour à une bipolarisation** centre (Macron) versus gauche élargie, avec l'extrême-droite intégrée comme nuance verticale plutôt que comme bloc autonome.\n\nCette évolution montre le **passage d'un clivage gauche-droite classique** (2012) vers une **triangulation politique** (2017) puis vers une **nouvelle bipolarisation centre-gauche** (2022)\n\n### Rapprochement Centre-Droite en 2022\n\n### \n\n```{r}\n#| label: correlations\n#| appendix: true\ndata_2022 <- read_parquet(\"DataClean/presidentielles_2022_1t.parquet\")\nscore_familles_2022 <- score(data_2022,\n                             familles_nuance)\n\ncor_familles_2022 <- cor(score_familles_2022[, names(familles_nuance)])\n    corrplot_famille <- corrplot(cor_familles_2022, method = \"color\",\n                                 type = \"upper\",\n                                 addCoef.col = \"black\", tl.col = \"black\",\n                                 tl.srt = 45,\n             title = \"Corrélations familles politiques 2022\", mar = c(0,0,1,0))\n    \n\n```\n\nL'analyse suggère un retour vers un clivage similaire à 2012. Le graphique des variables PCA montre la proximité du centre et de la droite sur PC1, qui structure l'opposition gauche-droite. La matrice de corrélations confirme cette observation avec un coefficient de 0,75 entre ces deux familles politiques.\n\nCette forte corrélation indique une convergence électorale centre-droite rappelant les dynamiques de 2012, interrogeant ainsi l'évolution du paysage politique parisien.\n\n## Analyse des Corrélations Canoniques (CCA)\n\n### Objectif et méthodologie\n\nL'Analyse des Corrélations Canoniques mesure la stabilité électorale en comparant les bureaux de vote entre deux élections consécutives. Elle identifie les bureaux de vote ayant maintenu des comportements électoraux cohérents versus ceux ayant connu des basculements significatifs.\n\nLa méthodologie comprend :\n\n-   **Normalisation** : Conversion des scores en pourcentages par bureau de vote\n\n-   **Jointure** : Jointure naturel des données par identifiant de bureau (id_bvote)\n\n-   **CCA** : Calcul des corrélations canoniques et scores canoniques\n\n-   **Identification** : Bureaux instables\n\n### Résultats des comparaisons temporelles\n\n**Stabilité 2017-2022**\n\n```{r}\n#| label: CCA_2022\n#| appendix: true\n#| warning: false\n# Fonction pour analyser la stabilité électorale entre deux élections\nanalyser_stabilite_electorale <- function(data_A_path, data_B_path, anneeA, anneeB,\n                                          familles ) {\n  \n  donnees_A <- read_parquet(data_A_path)\n  donnees_B <- read_parquet(data_B_path)\n  \n  scores_A <- score(donnees_A, familles)\n  scores_B <- score(donnees_B, familles)\n  \n  # Calcul des pourcentages\n  variables_familles <- names(familles)\n  \n  #Mettre le score en pourcentage pour rendre cela a la même echelle\n  scores_A_pct <- scores_A %>%\n    mutate(across(all_of(variables_familles), \n                  ~ round(.x / nb_exprime * 100, 2))) %>%\n    select(id_bvote, paste0(variables_familles))\n  \n  scores_B_pct <- scores_B %>%\n    mutate(across(all_of(variables_familles), \n                  ~ round(.x / nb_exprime * 100, 2))) %>%\n    select(id_bvote, paste0(variables_familles))\n  \n  donnees_jointes <- inner_join(scores_A_pct, scores_B_pct, \n                                by = \"id_bvote\", suffix = c(\"_x\",\"_y\"))\n  \n  variables_x <- paste0(variables_familles, \"_x\")\n  variables_y <- paste0(variables_familles, \"_y\")\n  \n  # Filtrer les variables avec de la variance\n  variables_x_valides <- variables_x[sapply(donnees_jointes[variables_x], \n                                            function(x) var(x, na.rm = TRUE) > 0)]\n  variables_y_valides <- variables_y[sapply(donnees_jointes[variables_y], \n                                            function(x) var(x, na.rm = TRUE) > 0)]\n  \n  X <- as.matrix(donnees_jointes[, variables_x_valides])\n  Y <- as.matrix(donnees_jointes[, variables_y_valides])\n  \n  # Analyse Canonique\n  cca_resultat <- cc(X, Y)\n  correlations <- round(cca_resultat$cor, 4)\n  \n  # Interprétation de la stabilité\n  stabilite_globale <- correlations[1]\n  \n  # Calcul des scores canoniques\n  scores_canoniques_x <- X %*% cca_resultat$xcoef[, 1]\n  scores_canoniques_y <- Y %*% cca_resultat$ycoef[, 1]\n  \n  # Distance à la diagonale \n  distance_diagonale <- abs(scores_canoniques_x - scores_canoniques_y)\n  donnees_jointes$distance_diagonale <- distance_diagonale\n  donnees_jointes$score_x <- scores_canoniques_x\n  donnees_jointes$score_y <- scores_canoniques_y\n  \n  # Identification des bureaux les plus/moins stables\n  seuil_stabilite <- quantile(distance_diagonale, 0.9)\n  bureaux_instables <- donnees_jointes[distance_diagonale > seuil_stabilite, ]\n  \n  # Graphique diagonale de stabilité\n  p1 <- ggplot(donnees_jointes, aes(x = score_x, y = score_y)) +\n  geom_point(aes(color = distance_diagonale), alpha = 0.6, size = 1.5) +\n  geom_abline(slope = 1, intercept = 0, linetype = \"dashed\", color = \"red\", size = 1) +\n  labs(title = \"Stabilité électorale par bureau de vote \",\n       subtitle = paste0(\"Corrélation canonique: \", round(stabilite_globale, 3)),\n       x = paste0(\"Score canonique \", anneeA, \" (1er tour)\"),\n       y = paste0(\"Score canonique \", anneeB, \" (1er tour)\")) +\n  theme_minimal() +\n  theme(plot.title = element_text(hjust = 0.5),\n        plot.subtitle = element_text(hjust = 0.5))\n  \n  print(p1)\n  \n  tablo <- kable(bureaux_instables %>% \n            select(id_bvote, distance_diagonale, score_x, score_y) %>%\n            arrange(desc(distance_diagonale)) %>%\n            head(10),\n            col.names = c(\"Bureau de vote\", \"Distance diagonale\", \n                         paste0(\"Score \", anneeA), paste0(\"Score \", anneeB)),\n            digits = 3,\n            caption = paste0(\"Top 10 des bureaux les plus instables\"))\n  print(tablo)\n  \n  return()\n  \n}\n  resultat_stabilite <- analyser_stabilite_electorale(\n                      \"DataClean/presidentielles_2022_1t.parquet\",\n                      \"DataClean/presidentielles_2017_1t.parquet\",\n                      \"2022\",\n                      \"2017\",\n                       familles_nuance\n)\n    \n```\n\nLa corrélation canonique de **0,992** révèle une **fidélité électorale exceptionnelle** : la quasi-totalité des bureaux maintient un positionnement cohérent sur l'axe gauche-droite entre les deux scrutins.\n\nLe nuage de points s'aligne parfaitement sur la diagonale, confirmant que les bureaux conservent leur position relative. Dans cette analyse, les **scores faibles correspondent aux profils de gauche** (coefficients CCA négatifs pour PS/LFI) et les **scores élevés aux profils centre-droite** (coefficients CCA positifs pour LR/RN/En Marche) - cette convention étant déterminée par l'algorithme CCA.\n\nOn constate que les bureaux instable se caractérisés par un **basculement gauche centre-droite** : scores 2017 très négatifs versus scores 2022 très positifs.\n\nLe **13e arrondissement** concentre les plus fortes instabilités avec **3 bureaux dans le top 10**, dont le **bureau le plus instable** (13-33). Cela représente des \"poches de bascule\".\n\n```{r}\n#| label: CCA_2017\n#| appendix: true\n  resultat_stabilite <- analyser_stabilite_electorale(\n                      \"DataClean/presidentielles_2017_1t.parquet\",\n                      \"DataClean/presidentielles_2012_1t.parquet\",\n                      \"2017\",\n                      \"2012\",\n                       familles_nuance\n)\n```\n\nLa corrélation canonique de **0,949** indique une **forte stabilité électorale** entre ces deux scrutins.\n\n\\\nLe nuage de points se concentre majoritairement sur la diagonale, confirmant que les bureaux conservent leur positionnement relatif sur l'axe gauche-droite. Cependant, la stabilité est légèrement moindre qu'en 2017-2022.\n\nLes **10 bureaux les plus instables** présentent tous un **basculement gauche → centre-droite** : scores 2012 faibles (profil très à gauche/extrême) versus scores 2017 élevés (profil centre-droite). Le **17e arrondissement** domine avec plusieurs bureaux instables, illustrant des mutations locales où d'anciens bastions de gauche se sont convertis en zones centre-droite.\n\n## **Synthèse générale : Une méthodologie robuste pour comprendre les dynamiques électorales**\n\n**1. Validation méthodologique** Cette analyse démontre l'efficacité des **méthodes de factorisation matricielle (SVD/PCA/CCA)** pour l'analyse électorale :\n\n-   **PCA** : révèle les structures politiques et leur évolution temporelle\n\n-   **CCA** : quantifie précisément la stabilité électorale entre scrutins\n\n-   **Pipeline de nettoyage** : harmonise les données multi-temporelles\n\n**2. Découvertes sur le paysage politique parisien (2012-2022)**\n\n**Évolution structurelle en trois phases :**\n\n-   **2012** : Bipolarisation traditionnelle (droite modérée vs bloc gauche/écolo)\n\n-   **2017** : **Tripartition politique** (LR, PS/LFI, FN) - éclatement du système\n\n-   **2022** : **Nouvelle bipolarisation** (centre macroniste vs gauche élargie)\n\n**Stabilité paradoxale :**\n\n-   **Fidélité globale exceptionnelle** (corrélations 0,949 et 0,992)\n\n-   Mais **recompositions géographiquement concentrées** (13e, 17e arrondissements)\n\n-   **Direction unique des basculements** : gauche → centre-droite\n\n# **Appendix**\n\n```{r}\n#| label: appendix\n#| ref.label: !expr knitr::all_labels(appendix==TRUE)\n#| echo: true\n#| eval: false\n```\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":false,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"collapse":false,"message":false,"engine":"knitr"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","toc":true,"number-sections":true,"output-file":"rapport.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.6.42","editor":"visual","title":"Analyse multivariée des élections présidentielles : Méthodes PCA et CCA","author":"Asso et Antony","date":"`r Sys.Date()`"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":[]}